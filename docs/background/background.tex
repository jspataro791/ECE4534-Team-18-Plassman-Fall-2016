\documentclass[12pt,letterpaper]{article}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\author{Andrew Bryant, Danny Dutton, Benjamin Singleton, John Spataro}
\title{Team 18 Background Research}
\begin{document}
\maketitle

\section{Network Communication}

\section{Line Following}
The SparkFun Line Following Array (LFA) is a device designed to provide information on the location of a line within the array. The sensor works by relaying information about the eight sensor "eyes", specifically which eye is currently sensing a contrasted line. 

The LFA is attached to the front of the rover. Its maximum detectable line width is 3/4 of an inch. The power source for the LFA is 5V at a maximum of 185mA. 

The protocol for the LFA is I2C. Example code is given in a Github repository provided with the LFA. Features of the LFA include a physically adjustable sensitivity potentiometer and toggleable sensors. 

Sunlight and shadowing can cause issues with LFA devices. Shadowing presents a false-contrast condition, while sunlight can overwhelm the sensor array with UV light, causing sporadic readings. In fact, it is useful to low-pass filter the results of the sensor in software to prevent such issues and tightly control the lighting environment.

Another issue with LFA devices is the case where no line is detected at all. In this case, information about the last known line position needs to be taken into account, or the LFA will cause a rover to lose its location. This is usually done by keeping a record of some previous sensor states, and when the "no detection" state occurs the record must be accessed to determine the best route to relocation.

\section{Path Finding}

\section{Pixycam}
The Pixycam is a small camera that allows you to interpret your surroundings. It can differentiate colors, and can be programmed to look for specific shapes and color cues, as well as calculating angles. It was developed by Carnegie Mellon University and Charmed Labs, and can interpret its surroundings using much less processing power than interpreting a normal camera’s input. 

The Pixycam would be attached to the ceiling above the playing field. It will be used to tell the location and direction of the rovers. This will allow the ‘ghost’ rover to make intelligent decisions about how to best chase the ‘Pacman’ rover. 

The Pixycam can be used with a variety of communication protocols, including I2C and UART. The Pixycam comes with software that can already interpret things such as balls or blocks, but is also programmable to look for user defined objects. It is compatible with a variety of devices, including most microprocessors. 

There are some potential problems and limitations to the Pixycam that must be accounted for. It provides fifty frames per second, so if the Pixycam misreads something one frame, code needs to be used to prevent the anomalies from misdirecting the ‘ghost’ rover. Also, since the Pixycam will be used from a relatively moderate distance, there must be measures taken to tell the true distance an object is using mostly basic trigonometry. 


\end{document}
